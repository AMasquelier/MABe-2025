{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8c041e-eb40-4a45-8306-c956fb271bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "from models import ARModel\n",
    "from augmentation import *\n",
    "from utils import set_seed\n",
    "from dataset import MABeDataset, create_dataloaders\n",
    "from metrics import BCE, F1_score\n",
    "from trainer import Trainer\n",
    "\n",
    "os.makedirs('deliveries', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('history', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb15b762-cf07-457c-b457-50e263e07a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../Datasets/MABe-mouse-behavior-detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a026cf9f-28eb-44e3-8071-9984e4eb6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model':ARModel,\n",
    "    'num_workers':24,\n",
    "    'seed':2,\n",
    "    'batch_size':64,\n",
    "    'losses':[\n",
    "        BCE(),        \n",
    "    ],\n",
    "    'metrics': [\n",
    "        F1_score\n",
    "    ],\n",
    "    'verbose':2,\n",
    "    'train_only':False,\n",
    "    'scheduler':True,\n",
    "    \"lr\":1e-4,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777cdcd-7b23-4eab-8328-9821b294d20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21bc5787-2736-4e4b-9582-d54538851109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23cc91ea1830934d4f2a8369495574375ff96b93efc9fc018e6aacc59d22403d \n",
      "\n",
      "\u001b[1m Epoch 71/2048\n",
      "\u001b[1m Training \t|\t loss=1.05726\u001b[0m\n",
      "\u001b[1m Validation \t|\t loss=0.279416 F1_score=0.145\u001b[0m\n",
      "\n",
      "\u001b[1m Best : F1_score=0.153 at epoch 69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                          | 0/17 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m trainer = Trainer(config=config)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2048\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/1826F7D426F7B13C/Jupyter/MABe/trainer.py:163\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, epochs, checkpoint_freq, Lab, config, model)\u001b[39m\n\u001b[32m    160\u001b[39m mlflow.log_params(\u001b[38;5;28mself\u001b[39m.config)\n\u001b[32m    161\u001b[39m mlflow.log_params({\u001b[33m\"\u001b[39m\u001b[33mepochs\u001b[39m\u001b[33m\"\u001b[39m:epochs, \u001b[33m\"\u001b[39m\u001b[33mmodel_id\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28mself\u001b[39m.exp_id})\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m train_loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mtrain_only\u001b[39m\u001b[33m'\u001b[39m]: \n\u001b[32m    166\u001b[39m     val_scores, val_loss = \u001b[38;5;28mself\u001b[39m.validate(err_analysis=(epoch==epochs-\u001b[32m1\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/1826F7D426F7B13C/Jupyter/MABe/trainer.py:68\u001b[39m, in \u001b[36mTrainer.train_one_epoch\u001b[39m\u001b[34m(self, epoch)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config[\u001b[33m'\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m'\u001b[39m]==\u001b[32m2\u001b[39m: pbar = tqdm(\u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_loader), total=n_steps, desc=\u001b[33m\"\u001b[39m\u001b[33mTraining\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m: pbar = \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.train_loader)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mavail_lbl\u001b[49m\u001b[43m,\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:735\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    733\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    734\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    738\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    740\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    741\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1493\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1490\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1492\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1493\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1495\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1496\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1445\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1443\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1444\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1445\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1446\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1447\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1286\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1274\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1275\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1283\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1284\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1285\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1286\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1287\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1288\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1290\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1291\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/queue.py:180\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m    179\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnot_empty\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m item = \u001b[38;5;28mself\u001b[39m._get()\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m.not_full.notify()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/threading.py:359\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    358\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         gotit = \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    360\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    361\u001b[39m         gotit = waiter.acquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config=config)\n",
    "model = trainer.train(epochs=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb950a-9d7c-41dd-ad4e-a20e1de43c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fold in range(1,5):\n",
    "#     trainer = Trainer(config=config, fold=fold)\n",
    "#     model = trainer.train(epochs=2048*2)\n",
    "#     torch.save(model.state_dict(), f\"models/{trainer.exp_id}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f69b1a-1671-4766-8c1c-6d8881aa92eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e6621-e7ef-4386-82bf-1ff66afc02f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce501f3c-08d4-4cf3-8765-b1036ee9a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = trainer.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80c91f-aeb4-498f-b9ef-76fae8dd16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"models/{trainer.exp_id}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d02c8-9493-4778-a781-fb5b629f394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f\"models/{trainer.exp_id}.pth\", map_location=torch.device(device)))\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499f671-fd7f-4a4b-8d94-5135402faf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "PATH = '../../Datasets/MABe-mouse-behavior-detection/'\n",
    "df = pd.read_csv(PATH+'train.csv')\n",
    "\n",
    "for m in range(4):\n",
    "    df[f'mouse{m+1}_condition'] = df[f'mouse{m+1}_condition'].apply(ds.process_condition)\n",
    "    df[f'mouse{m+1}_age'] = df[f'mouse{m+1}_age'].apply(ds.process_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5ca04-f6cd-4422-85cc-d2ff8318b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_bp = np.array(['ear_left','ear_right', 'lateral_left','lateral_right','neck','nose','tail_base']).astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b757021-becf-481b-9d85-d0424810b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['lab_id', 'video_id', 'mouse_1', 'mouse_2', 'chunk', 'ok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8dc9fa-82ce-40cd-9f0b-39cfbc9240af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocess, base_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bffa95-afd2-4b60-bf30-bdba86ab1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_track(track, fps):\n",
    "    pdist = torch.nn.PairwiseDistance(p=2)\n",
    "\n",
    "    x = torch.tensor(np.stack([np.stack([np.array(_x) for _x in x]) for x in track.values]))\n",
    "    if x.size(1)==7: x = torch.cat([x,x], dim=1)\n",
    "    \n",
    "\n",
    "    resize_x = torchvision.transforms.Resize((int(len(x)*(30./fps)), 2))\n",
    "    \n",
    "    x_ = []\n",
    "    for i in range(14):\n",
    "        x_.append(resize_x(x[:,i].unsqueeze(0))[0].unsqueeze(1) / ppc)\n",
    "    x = torch.cat(x_, dim=1)\n",
    "    \n",
    "    return x.float()\n",
    "\n",
    "\n",
    "def get_behaviors_labeled(x):\n",
    "    if isinstance(x, str):\n",
    "        B = {}\n",
    "        X = eval(x)\n",
    "        for x in X:\n",
    "            m1,m2,b = x.split(',')\n",
    "            if (m1,m2) in B: B[(m1,m2)].append(b.replace('\"', '').replace(\"'\", ''))\n",
    "            else: B[(m1,m2)] = [b.replace('\"', '').replace(\"'\", '')]\n",
    "\n",
    "        for p in B:\n",
    "            vec = torch.zeros((len(LABELS)))\n",
    "            for x in B[p]: vec[LABELS.index(x)] = 1\n",
    "            vec[-1]=1\n",
    "            B[p] = vec\n",
    "        return B\n",
    "    return {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adcd9c8-d736-453d-9c38-dd5214ee96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobile_average(x, kernel=[0.05,0.1,0.2,0.3,0.2,0.1,0.05]):\n",
    "    kernel = torch.tensor(kernel)\n",
    "    for _ in range(len(x.shape)-1): kernel = kernel.unsqueeze(-1)\n",
    "    k_size = len(kernel)//2\n",
    "    N = x.size(0)\n",
    "    out = x.clone()\n",
    "    for i in range(k_size, N-k_size):\n",
    "        out[i] = torch.multiply(x[i-k_size:i+k_size+1], kernel).sum(dim=0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f98b0-3f9c-4a15-91de-fd5c8a23bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Pred = pd.DataFrame(columns=['row_id','video_id','agent_id','target_id','action','start_frame','stop_frame'])\n",
    "model.eval()\n",
    "\n",
    "\n",
    "for idx in tqdm(df.index[1:2]):\n",
    "    filepath = f'{df.loc[idx, 'lab_id']}/{df.loc[idx, 'video_id']}'\n",
    "    track = pd.read_parquet(PATH+f'train_tracking/{filepath}.parquet')\n",
    "    annot = pd.read_parquet(PATH+f'train_annotation/{filepath}.parquet')\n",
    "    annot['video_id'] = df.loc[idx, 'video_id']\n",
    "    annot['lab_id'] = df.loc[idx, 'lab_id']\n",
    "    annot['behaviors_labeled'] = df.loc[idx, 'behaviors_labeled']\n",
    "\n",
    "    annot['agent_id'] = 'mouse'+annot['agent_id'].astype('str')\n",
    "    annot['target_id'] = 'mouse'+annot['target_id'].astype('str')\n",
    "    annot.loc[annot['agent_id']==annot['target_id'], 'target_id'] = 'self'\n",
    "\n",
    "\n",
    "    fps = df.loc[idx, 'frames_per_second']\n",
    "    ppc = df.loc[idx, 'pix_per_cm_approx']\n",
    "    min_coord = np.array([track.x.min(), track.y.min()])\n",
    "    arena_w,arena_h = np.array([track.x.max(), track.y.max()])-min_coord\n",
    "    \n",
    "\n",
    "    Behaviors = get_behaviors_labeled(df.loc[idx, 'behaviors_labeled'])\n",
    "    track, _, Mice = preprocess(track, None)\n",
    "\n",
    "    resize_back = torchvision.transforms.Resize((len(track), 37))\n",
    "\n",
    "\n",
    "    for c in track.columns:\n",
    "        track[c] = track[c].apply(lambda x: x if (isinstance(x, np.ndarray) and pd.isna([x]).sum()==0) else np.array([0., 0.]))\n",
    "\n",
    "    context = torch.tensor([\n",
    "        float(df.loc[idx,'arena_shape']=='circular'),\n",
    "        arena_w/ppc,\n",
    "        arena_h/ppc,\n",
    "    ]).float().unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "    n_feat = 14\n",
    "    seq_len = 1024\n",
    "    min_size = 8\n",
    "\n",
    "    for m1 in Mice:\n",
    "        for m2 in Mice:\n",
    "            cols = list(base_bp + ' - ' + str(m1))\n",
    "            if m1!=m2: cols += list(base_bp + ' - ' + str(m2))\n",
    "            out = track[cols]\n",
    "\n",
    "            M1 = f'mouse{m1}'\n",
    "            M2 = f'mouse{m2}' if m1!=m2 else 'self'\n",
    "\n",
    "            if not ((M1,M2) in Behaviors): continue\n",
    "\n",
    "            with torch.no_grad():\n",
    "                X = load_track(out, fps).to(device)\n",
    "                length = len(X)\n",
    "                X = torch.cat([X, torch.zeros((seq_len-(X.size(0)%seq_len),n_feat,2)).to(device)], dim=0)\n",
    "                X = X.reshape((X.size(0)//seq_len, seq_len, n_feat, 2)).transpose(1,2)\n",
    "\n",
    "                yp = torch.zeros((X.size(0), 37, seq_len)).to(device)\n",
    "                yp = model(X,context.repeat(X.size(0),1)).sigmoid()\n",
    "                yp = yp.transpose(1,2).flatten(0,1).cpu()\n",
    "                yp = yp * Behaviors[(M1,M2)][:-1]\n",
    "\n",
    "                yp = resize_back(yp[:length].unsqueeze(0))[0]\n",
    "                \n",
    "            # yp = mobile_average(yp)\n",
    "            \n",
    "            last = (-1, 37)\n",
    "            P = []\n",
    "            for i,(m,p) in enumerate(zip(*yp.max(dim=1))):\n",
    "                p = int(p) if m>.01 else 37\n",
    "                if last[1]!=p:  \n",
    "                    \n",
    "                    p_len = len(Pred)\n",
    "                    # Add action\n",
    "                    if last[1]!=37 and (i-last[0]>min_size or len(P)==0):\n",
    "                        Pred.loc[p_len] = [p_len, df.loc[idx, 'video_id'], M1, M2, LABELS[last[1]], last[0], i-1]\n",
    "                        P.append(last)\n",
    "                        last = (i,int(p))\n",
    "                    elif i-last[0]<=min_size and P:\n",
    "                        last = P[-1]\n",
    "                    else:\n",
    "                        P.append(last)\n",
    "                        last = (i,int(p))\n",
    "                \n",
    "            if last[1] and last[1]!=37 and i-last[0]>min_size:\n",
    "                Pred.loc[len(Pred)] = [len(Pred), df.loc[idx, 'video_id'], M1, M2, LABELS[last[1]], last[0], i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa923a32-f369-4320-8505-b2531b495b5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "class HostVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1) -> float:\n",
    "    label_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
    "    prediction_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
    "\n",
    "    for row in lab_solution.to_dicts():\n",
    "        label_frames[row['label_key']].update(range(row['start_frame'], row['stop_frame']))\n",
    "\n",
    "    for video in lab_solution['video_id'].unique():\n",
    "        \n",
    "        active_labels: str = lab_solution.filter(pl.col('video_id') == video)['behaviors_labeled'].first()  # ty: ignore\n",
    "        active_labels: set[str] = set(json.loads(active_labels))\n",
    "        predicted_mouse_pairs: defaultdict[str, set[int]] = defaultdict(set)\n",
    "\n",
    "        for row in lab_submission.filter(pl.col('video_id') == video).to_dicts():\n",
    "            # Since the labels are sparse, we can't evaluate prediction keys not in the active labels.\n",
    "            if ','.join([str(row['agent_id']), str(row['target_id']), row['action']]) not in active_labels:\n",
    "                continue\n",
    "\n",
    "            new_frames = set(range(row['start_frame'], row['stop_frame']))\n",
    "            # Ignore truly redundant predictions.\n",
    "            new_frames = new_frames.difference(prediction_frames[row['prediction_key']])\n",
    "            prediction_pair = ','.join([str(row['agent_id']), str(row['target_id'])])\n",
    "            if predicted_mouse_pairs[prediction_pair].intersection(new_frames):\n",
    "                # A single agent can have multiple targets per frame (ex: evading all other mice) but only one action per target per frame.\n",
    "                raise HostVisibleError('Multiple predictions for the same frame from one agent/target pair')\n",
    "            prediction_frames[row['prediction_key']].update(new_frames)\n",
    "            predicted_mouse_pairs[prediction_pair].update(new_frames)\n",
    "            \n",
    "    tps = defaultdict(int)\n",
    "    fns = defaultdict(int)\n",
    "    fps = defaultdict(int)\n",
    "\n",
    "    #print(list(prediction_frames))\n",
    "    \n",
    "    for key, pred_frames in prediction_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        matched_label_frames = label_frames[key]\n",
    "        \n",
    "        tps[action] += len(pred_frames.intersection(matched_label_frames))\n",
    "        fns[action] += len(matched_label_frames.difference(pred_frames))\n",
    "        fps[action] += len(pred_frames.difference(matched_label_frames))\n",
    "\n",
    "        # print(action, len(pred_frames), len(matched_label_frames))\n",
    "        # print(len(pred_frames.intersection(matched_label_frames)), len(matched_label_frames.difference(pred_frames)), len(pred_frames.difference(matched_label_frames)))\n",
    "        # print()\n",
    "\n",
    "    distinct_actions = set()\n",
    "    for key, frames in label_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        distinct_actions.add(action)\n",
    "        if key not in prediction_frames:\n",
    "            fns[action] += len(frames)\n",
    "\n",
    "    action_f1s = []\n",
    "    for action in distinct_actions:\n",
    "        if tps[action] + fns[action] + fps[action] == 0:\n",
    "            action_f1s.append(0)\n",
    "        else:\n",
    "            action_f1s.append((1 + beta**2) * tps[action] / ((1 + beta**2) * tps[action] + beta**2 * fns[action] + fps[action]))\n",
    "    \n",
    "    print(action_f1s)\n",
    "    return sum(action_f1s) / len(action_f1s)\n",
    "\n",
    "\n",
    "def mouse_fbeta(solution: pd.DataFrame, submission: pd.DataFrame, beta: float = 1) -> float:\n",
    "    \n",
    "    if len(solution) == 0 or len(submission) == 0:\n",
    "        raise ValueError('Missing solution or submission data')\n",
    "\n",
    "    expected_cols = ['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n",
    "\n",
    "    for col in expected_cols:\n",
    "        if col not in solution.columns:\n",
    "            raise ValueError(f'Solution is missing column {col}')\n",
    "        if col not in submission.columns:\n",
    "            raise ValueError(f'Submission is missing column {col}')\n",
    "\n",
    "    solution: pl.DataFrame = pl.DataFrame(solution)\n",
    "    submission: pl.DataFrame = pl.DataFrame(submission)\n",
    "    assert (solution['start_frame'] <= solution['stop_frame']).all()\n",
    "    assert (submission['start_frame'] <= submission['stop_frame']).all()\n",
    "    solution_videos = set(solution['video_id'].unique())\n",
    "    # Need to align based on video IDs as we can't rely on the row IDs for handling public/private splits.\n",
    "    submission = submission.filter(pl.col('video_id').is_in(solution_videos))\n",
    "\n",
    "    solution = solution.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('label_key'),\n",
    "    )\n",
    "    submission = submission.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('prediction_key'),\n",
    "    )\n",
    "\n",
    "    lab_scores = []\n",
    "    for lab in solution['lab_id'].unique():\n",
    "        lab_solution = solution.filter(pl.col('lab_id') == lab).clone()\n",
    "        lab_videos = set(lab_solution['video_id'].unique())\n",
    "        lab_submission = submission.filter(pl.col('video_id').is_in(lab_videos)).clone()\n",
    "        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n",
    "\n",
    "    return sum(lab_scores) / len(lab_scores)\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, beta: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    F1 score for the MABe Challenge\n",
    "    \"\"\"\n",
    "    solution = solution.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    submission = submission.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    return mouse_fbeta(solution, submission, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d78ab-9641-4c86-81ae-867bb290c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred['lab_id'] = 'lab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ded07-16ee-4916-8799-d155a79d2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pred = Pred[Pred.start_frame<2048]\n",
    "#annot = annot[annot.start_frame<2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce5682-82a4-4d6a-8b23-928ba5edcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score(annot, Pred, 'row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ef134-57ea-4ab5-b401-d064eba96d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = idx\n",
    "(df.loc[i, 'lab_id'] + ' - ' + str(df.loc[i, 'video_id'])) in ds.DF.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761f6ee-8f44-409f-9f85-9bcf87b1597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f17014-a72f-4d59-b5f6-d964d523b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d88bd-a3c0-49cf-a256-883788f9acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.animation as animation\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "# plt.rcParams['figure.dpi'] = 128  \n",
    "# plt.ioff()\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# colors = plt.cm.tab10.colors\n",
    "\n",
    "# def update(frame):\n",
    "#     plt.cla()\n",
    "    \n",
    "#     loc = x.cpu().transpose(0,-1)\n",
    "#     plt.scatter(loc[0,frame,:7], loc[1,frame,:7], c=colors[0])\n",
    "#     plt.scatter(loc[0,frame,7:], loc[1,frame,7:], c=colors[1])\n",
    "\n",
    "    \n",
    "#     if y[frame].max()>.5:\n",
    "#         plt.text(1,1, LABELS[np.argmax(y[frame])], color=colors[0])\n",
    "#     plt.xlim(0, 100)\n",
    "#     plt.ylim(0, 100)\n",
    "\n",
    "\n",
    "# ani = animation.FuncAnimation(fig=fig, func=update, frames=x.size(1), interval=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07968907-690e-4e3a-809e-5e858483dbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e96705-ed55-4619-955c-32b914a6b412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29595d-fb46-4039-93d1-0ff5cc2e3e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc97748f-4eb6-4178-86c6-1a0c6ae8c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Pred = pd.DataFrame(columns=['row_id','video_id','agent_id','target_id','action','start_frame','stop_frame'])\n",
    "df = pd.read_csv(PATH+'test.csv')\n",
    "\n",
    "for idx in tqdm(df.index):\n",
    "    filepath = f\"{df.loc[idx, 'lab_id']}/{df.loc[idx, 'video_id']}\"\n",
    "    track = pd.read_parquet(PATH+f'test_tracking/{filepath}.parquet')\n",
    "\n",
    "    fps = df.loc[idx, 'frames_per_second']\n",
    "    ppc = df.loc[idx, 'pix_per_cm_approx']\n",
    "    min_coord = np.array([track.x.min(), track.y.min()])\n",
    "    arena_w,arena_h = np.array([track.x.max(), track.y.max()])-min_coord\n",
    "    \n",
    "\n",
    "    Behaviors = get_behaviors_labeled(df.loc[idx, 'behaviors_labeled'])\n",
    "    track, _, Mice = preprocess(track, None)\n",
    "\n",
    "    resize_back = torchvision.transforms.Resize((len(track), 37))\n",
    "\n",
    "\n",
    "    for c in track.columns:\n",
    "        track[c] = track[c].apply(lambda x: x-min_coord if (isinstance(x, np.ndarray) and pd.isna([x]).sum()==0) else np.array([0., 0.]))\n",
    "\n",
    "    context = torch.tensor([\n",
    "        float(df.loc[idx,'arena_shape']=='circular'),\n",
    "        arena_w/ppc,\n",
    "        arena_h/ppc,\n",
    "    ]).float().unsqueeze(0).to(device)\n",
    "\n",
    "    n_feat = 14\n",
    "    seq_len = 1024\n",
    "    min_size = 8\n",
    "\n",
    "    for m1 in Mice:\n",
    "        for m2 in Mice:\n",
    "            cols = list(base_bp + ' - ' + str(m1))\n",
    "            if m1!=m2: cols += list(base_bp + ' - ' + str(m2))\n",
    "            out = track[cols]\n",
    "\n",
    "            M1 = f'mouse{m1}'\n",
    "            M2 = f'mouse{m2}' if m1!=m2 else 'self'\n",
    "\n",
    "            if not ((M1,M2) in Behaviors): continue\n",
    "\n",
    "            with torch.no_grad():\n",
    "                X = load_track(out, fps).to(device)\n",
    "                length = len(X)\n",
    "                X = torch.cat([X, torch.zeros((seq_len-(X.size(0)%seq_len),n_feat,2)).to(device)], dim=0)\n",
    "                X = X.reshape((X.size(0)//seq_len, seq_len, n_feat, 2)).transpose(1,2)\n",
    "\n",
    "                yp = torch.zeros((X.size(0), 37, seq_len)).to(device)\n",
    "                yp = model(X,context.repeat(X.size(0),1)).sigmoid()\n",
    "                yp = yp.transpose(1,2).flatten(0,1).cpu()\n",
    "                yp = yp * Behaviors[(M1,M2)][:-1]\n",
    "\n",
    "                yp = resize_back(yp[:length].unsqueeze(0))[0]\n",
    "                \n",
    "            # yp = mobile_average(yp)\n",
    "            \n",
    "            last = (-1, 37)\n",
    "            P = []\n",
    "            for i,(m,p) in enumerate(zip(*yp.max(dim=1))):\n",
    "                p = int(p) if m>.2 else 37\n",
    "                if last[1]!=p:  \n",
    "                    \n",
    "                    p_len = len(Pred)\n",
    "                    # Add action\n",
    "                    if last[1]!=37 and (i-last[0]>min_size or len(P)==0):\n",
    "                        Pred.loc[p_len] = [p_len, df.loc[idx, 'video_id'], M1, M2, LABELS[last[1]], last[0], i-1]\n",
    "                        P.append(last)\n",
    "                        last = (i,int(p))\n",
    "                    elif i-last[0]<=min_size and P:\n",
    "                        last = P[-1]\n",
    "                    else:\n",
    "                        P.append(last)\n",
    "                        last = (i,int(p))\n",
    "                \n",
    "            if last[1] and last[1]!=37 and i-last[0]>min_size:\n",
    "                Pred.loc[len(Pred)] = [len(Pred), df.loc[idx, 'video_id'], M1, M2, LABELS[last[1]], last[0], i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79320fb-5176-4e1c-a68c-84c2a8060c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = Pred.drop_duplicates(subset=['video_id', 'agent_id', 'target_id', 'action', 'start_frame'], keep='last')\n",
    "Pred.row_id = np.arange(len(Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e4070d-5513-4e2f-930e-a054d67a8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db4b81b-8ce1-488d-9211-c3aec915132e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7542f27-ad89-4f5f-8960-a0b4008b3d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff3a4e-7aec-4714-ad33-5855f1e78882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef472df-d8fe-4904-8396-8f1cfba57765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6586ebe8-accf-4020-b8d7-b3973d19ecfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdb95ea-45c3-4981-b93c-c19008562206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7586d47e-6db6-4cc6-aeeb-b782bebe1922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6aa40-bbb8-42b2-b552-27a03188bc54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
