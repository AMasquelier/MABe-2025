{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8c041e-eb40-4a45-8306-c956fb271bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "\n",
    "from models import *\n",
    "from augmentation import *\n",
    "from utils import set_seed\n",
    "from dataset import MABeDataset, create_dataloaders\n",
    "from metrics import BCE, F1_score\n",
    "from trainer import Trainer\n",
    "\n",
    "os.makedirs('deliveries', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('history', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb15b762-cf07-457c-b457-50e263e07a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../Datasets/MABe-mouse-behavior-detection/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4489213b-4c03-4e15-88c2-20c22fd23063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1156 / 1156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['lab_id', 'video_id', 'mouse1_strain', 'mouse1_color', 'mouse1_sex',\n",
       "       'mouse1_id', 'mouse1_age', 'mouse1_condition', 'mouse2_strain',\n",
       "       'mouse2_color', 'mouse2_sex', 'mouse2_id', 'mouse2_age',\n",
       "       'mouse2_condition', 'mouse3_strain', 'mouse3_color', 'mouse3_sex',\n",
       "       'mouse3_id', 'mouse3_age', 'mouse3_condition', 'mouse4_strain',\n",
       "       'mouse4_color', 'mouse4_sex', 'mouse4_id', 'mouse4_age',\n",
       "       'mouse4_condition', 'frames_per_second', 'video_duration_sec',\n",
       "       'pix_per_cm_approx', 'video_width_pix', 'video_height_pix',\n",
       "       'arena_width_cm', 'arena_height_cm', 'arena_shape', 'arena_type',\n",
       "       'body_parts_tracked', 'behaviors_labeled', 'tracking_method', 'label',\n",
       "       'mouse_1', 'mouse_2', 'chunk', 'ok', 'arena_w', 'arena_h'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = MABeDataset()\n",
    "LABELS = ds.LABELS\n",
    "ds.DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de091f7-160e-48fd-a87d-39f7404e8611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 4#np.random.randint(1024)\n",
    "(x,al,c),y=ds[idx]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ebee0d-c059-4004-8005-1def3556892a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2de99f6f-47f4-4080-aa78-a6c6211b4324",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(ds.DF['label'].explode().dropna()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6843666d-1bc9-4903-9d85-48dd58c033ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_Engineering(nn.Module):\n",
    "    def __init__(self, config=None):\n",
    "        super().__init__()\n",
    "        if config: self.config.update(config)\n",
    "        self.pdist = torch.nn.PairwiseDistance(p=2)\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        B,C,N,_ = x.shape\n",
    "        C = C//2\n",
    "        x1 = x[:,:C]\n",
    "        x2 = x[:,C:]\n",
    "\n",
    "        \n",
    "        arena_wh = context[:,[-2,-1]].unsqueeze(1).unsqueeze(1).to(x.device)\n",
    "        zero = torch.zeros((1,1,1,2)).to(x.device)\n",
    "        circle = context[:,-3].unsqueeze(1).unsqueeze(1)\n",
    "\n",
    "        dist_wall_circle_1 = torch.abs((x1-arena_wh/2).norm(dim=-1)-context[:,-1].unsqueeze(1).unsqueeze(1)/2)\n",
    "        dist_wall_rect_1,_ = torch.cat([torch.abs(x1-arena_wh), torch.abs(x1-zero)], dim=-1).min(dim=-1)\n",
    "        dist_wall_1 = circle * dist_wall_circle_1 + (1-circle) * dist_wall_rect_1\n",
    "\n",
    "        dist_wall_circle_2 = torch.abs((x2-arena_wh/2).norm(dim=-1)-context[:,-1].unsqueeze(1).unsqueeze(1)/2)\n",
    "        dist_wall_rect_2,_ = torch.cat([torch.abs(x2-arena_wh), torch.abs(x2-zero)], dim=-1).min(dim=-1)\n",
    "        dist_wall_2 = circle * dist_wall_circle_2 + (1-circle) * dist_wall_rect_2\n",
    "        \n",
    "\n",
    "        rel_x = (x1-x2)\n",
    "        rel_dist = rel_x.norm(dim=-1)\n",
    "\n",
    "        dx1 = x1.diff(dim=2, prepend=x1[:, :, :1])\n",
    "        dx2 = x2.diff(dim=2, prepend=x2[:, :, :1])\n",
    "\n",
    "        adx1 = torch.einsum('...i,...i->...', dx1[:, :, 1:], dx1[:, :, :-1]) / (dx1[:, :, 1:].norm(dim=-1) * dx1[:, :, :-1].norm(dim=-1) + 1e-4)\n",
    "        adx1 = torch.cat([torch.zeros_like(adx1[:, :, :1]), adx1], dim=2)\n",
    "\n",
    "        adx2 = torch.einsum('...i,...i->...', dx2[:, :, 1:], dx2[:, :, :-1]) / (dx2[:, :, 1:].norm(dim=-1) * dx2[:, :, :-1].norm(dim=-1) + 1e-4)\n",
    "        adx2 = torch.cat([torch.zeros_like(adx2[:, :, :1]), adx2], dim=2)\n",
    "\n",
    "        dx1_thresh = (dx1.norm(dim=-1)>.1).float()\n",
    "        dx2_thresh = (dx2.norm(dim=-1)>.1).float()\n",
    "\n",
    "        dx1_= dx1.norm(dim=-1)\n",
    "        dx2_= dx2.norm(dim=-1)\n",
    "\n",
    "        ddx1 = dx1.diff(dim=2, prepend=dx1[:, :, :1])\n",
    "        ddx2 = dx2.diff(dim=2, prepend=dx2[:, :, :1])\n",
    "\n",
    "        cross_prod_1 = (dx1[:,:,:,[0]] * ddx1[:,:,:,[1]] - dx1[:,:,:,[1]] * ddx1[:,:,:,[0]]).squeeze(dim=-1)\n",
    "        cross_prod_2 = (dx2[:,:,:,[0]] * ddx2[:,:,:,[1]] - dx2[:,:,:,[1]] * ddx2[:,:,:,[0]]).squeeze(dim=-1)\n",
    "        \n",
    "        dirs = torch.einsum('...i,...i->...', dx1, dx2) / (dx1.norm(dim=-1) * dx2.norm(dim=-1) + 1e-6)\n",
    "        cross = (dx1[:,:,:,[0]] * dx2[:,:,:,[1]] - dx1[:,:,:,[1]] * dx2[:,:,:,[0]]).squeeze(dim=-1)\n",
    "        d = torch.cat([\n",
    "            self.pdist(x1.roll(i+1, dims=1), x2) #* mask_x1.roll(i+1, dims=1) * mask_x2\n",
    "        for i in range(x1.size(1))], dim=1)\n",
    "        \n",
    "        dd = d.diff(dim=-1, prepend=d[:, :, :1])\n",
    "\n",
    "\n",
    "        lead_1 = torch.einsum('...i,...i->...', dx1, rel_x) / (dx1.norm(dim=-1) * rel_x.norm(dim=-1) + 1e-6)\n",
    "        lead_2 = torch.einsum('...i,...i->...', dx2, -rel_x) / (dx2.norm(dim=-1) * rel_x.norm(dim=-1) + 1e-6)\n",
    "        drel_x = rel_x.diff(dim=2, prepend=rel_x[:, :, :1])\n",
    "\n",
    "        \n",
    "        tail_to_neck_1 = (x1[:, [6]] - x1[:, [4]])\n",
    "        neck_to_nose_1 = (x1[:, [4]] - x1[:, [5]])\n",
    "        tail_to_nose_1 = (x1[:, [6]] - x1[:, [5]])\n",
    "        head_angle_1 = torch.einsum('...i,...i->...', tail_to_neck_1, neck_to_nose_1) / (tail_to_neck_1.norm(dim=-1) * neck_to_nose_1.norm(dim=-1) + 1e-6)\n",
    "\n",
    "        tail_to_neck_2 = (x2[:, [6]] - x2[:, [4]])\n",
    "        neck_to_nose_2 = (x2[:, [4]] - x2[:, [5]])\n",
    "        tail_to_nose_2 = (x2[:, [6]] - x2[:, [5]])\n",
    "        head_angle_2 = torch.einsum('...i,...i->...', tail_to_neck_2, neck_to_nose_2) / (tail_to_neck_2.norm(dim=-1) * neck_to_nose_2.norm(dim=-1) + 1e-6)\n",
    "\n",
    "        ears_span_1 = (x1[:, [0]] - x1[:, [1]]).norm(dim=-1)\n",
    "        ears_span_2 = (x2[:, [0]] - x2[:, [1]]).norm(dim=-1)\n",
    "\n",
    "        len1 = (x1[:, -1] - x1[:, -2]).norm(dim=-1)\n",
    "        len2 = (x2[:, -1] - x2[:, -2]).norm(dim=-1)\n",
    "\n",
    "        # f_1 = torch.einsum('...i,...i->...', dx1, tail_to_nose_2) / (dx1.norm(dim=-1) * tail_to_nose_2.norm(dim=-1) + 1e-6)\n",
    "        # f_2 = torch.einsum('...i,...i->...', dx2, tail_to_nose_1) / (dx2.norm(dim=-1) * tail_to_nose_1.norm(dim=-1) + 1e-6)\n",
    "\n",
    "        # f_1 = f_1 * dx1_thresh\n",
    "        # f_2 = f_2 * dx2_thresh\n",
    "\n",
    "        # wh_ratio_1 = self.pdist(x1[:,[2]],x1[:,[3]])/self.pdist(x1[:,[5]],x1[:,[6]])\n",
    "        # wh_ratio_2 = self.pdist(x2[:,[2]],x2[:,[3]])/self.pdist(x2[:,[5]],x2[:,[6]])\n",
    "\n",
    "        x = torch.concat([dx1_, dx2_, cross_prod_1, cross_prod_2, adx1, adx2, dirs, d, dd, lead_1, lead_2, dist_wall_1, dist_wall_2], dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca1aa39c-a763-4ebc-aa7e-d0fea872fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feng = Feature_Engineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1803dbe-3380-4228-9aad-161adc67b8a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 175, 1024])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = feng(x.unsqueeze(0).repeat(64,1,1,1), c.unsqueeze(0).repeat(64,1))\n",
    "fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "426f17e4-615f-48f5-a598-4e9d47ee353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARModel(nn.Module):\n",
    "    def __init__(self, config=None):\n",
    "        super().__init__()\n",
    "        self.config = {\n",
    "        }\n",
    "        if config: self.config.update(config)\n",
    "\n",
    "        self.training = True\n",
    "\n",
    "        self.feature_eng = Feature_Engineering()\n",
    "        n_channels = 7\n",
    "        n_features = n_channels*(n_channels*2+11)\n",
    "\n",
    "        self.context_encoder = nn.Sequential(\n",
    "            nn.Linear(71, n_features),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        base_h_dim = 128\n",
    "\n",
    "        # self.unet = UNet(n_features, base_h_dim)\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            SEResConv(n_features, base_h_dim, 5, dilation=1, dropout=0.3),\n",
    "            nn.AvgPool1d(2),\n",
    "            SEResConv(base_h_dim, base_h_dim*2, 5, dilation=2, dropout=0.3),\n",
    "            nn.AvgPool1d(2),\n",
    "            SEResConv(base_h_dim*2, base_h_dim*4, 5, dilation=4, dropout=0.3),\n",
    "            # nn.AvgPool1d(2),\n",
    "            # Conv(base_h_dim*4, base_h_dim*8, 9),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            # Deconv(base_h_dim*8, base_h_dim*4, 9, padding=4),\n",
    "            # Upsample(1,2),\n",
    "            SEResDeconv(base_h_dim*4, base_h_dim*2, 5, padding=8, dilation=4, dropout=0.3),\n",
    "            Upsample(1,2),\n",
    "            SEResDeconv(base_h_dim*2, base_h_dim, 5, padding=4, dilation=2, dropout=0.3),\n",
    "            Upsample(1,2),\n",
    "            nn.ConvTranspose1d(base_h_dim, 37, 5, padding=2, dilation=1, bias=True),\n",
    "        )\n",
    "        #self.ca = CrossAttention(n_features, 7)\n",
    "\n",
    "\n",
    "    def forward(self, x, context):\n",
    "        x = self.feature_eng(x, context)\n",
    "        #c = self.context_encoder(context)\n",
    "        \n",
    "        #x = self.ca(x.transpose(-2,-1), c.unsqueeze(-2)).transpose(-2,-1)\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        # x = self.unet(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a026cf9f-28eb-44e3-8071-9984e4eb6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'model':ARModel,\n",
    "    'num_workers':24,\n",
    "    'seed':2,\n",
    "    'batch_size':64,\n",
    "    'losses':[\n",
    "        BCE(),        \n",
    "    ],\n",
    "    'metrics': [\n",
    "        F1_score\n",
    "    ],\n",
    "    'verbose':2,\n",
    "    'train_only':False,\n",
    "    'scheduler':True,\n",
    "    \"lr\":1e-4,    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777cdcd-7b23-4eab-8328-9821b294d20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bc5787-2736-4e4b-9582-d54538851109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de48ba5a94ad7fdbd0fbd49e92a5398575a05a7cd3c08b841148a73595cc8274 \n",
      "\n",
      "\u001b[1m Epoch 2261/4096\n",
      "\u001b[1m Training \t|\t loss=0.619079\u001b[0m\n",
      "\u001b[1m Validation \t|\t loss=0.189345 F1_score=0.447\u001b[0m\n",
      "\n",
      "\u001b[1m Best : F1_score=0.464 at epoch 2189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                          | 0/17 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(config=config)\n",
    "model = trainer.train(epochs=2048*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb950a-9d7c-41dd-ad4e-a20e1de43c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(6):\n",
    "#     if i!=2:\n",
    "#         trainer = Trainer(config=config|{\"seed\":i})\n",
    "#         model = trainer.train(epochs=2048*2)\n",
    "#         torch.save(model.state_dict(), f\"models/{trainer.exp_id}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f69b1a-1671-4766-8c1c-6d8881aa92eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e6621-e7ef-4386-82bf-1ff66afc02f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce501f3c-08d4-4cf3-8765-b1036ee9a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = trainer.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80c91f-aeb4-498f-b9ef-76fae8dd16ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"models/{trainer.exp_id}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d02c8-9493-4778-a781-fb5b629f394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f\"models/{trainer.exp_id}.pth\", map_location=torch.device(device)))\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499f671-fd7f-4a4b-8d94-5135402faf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "PATH = '../../Datasets/MABe-mouse-behavior-detection/'\n",
    "df = pd.read_csv(PATH+'train.csv')\n",
    "\n",
    "for m in range(4):\n",
    "    df[f'mouse{m+1}_condition'] = df[f'mouse{m+1}_condition'].apply(ds.process_condition)\n",
    "    df[f'mouse{m+1}_age'] = df[f'mouse{m+1}_age'].apply(ds.process_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e5ca04-f6cd-4422-85cc-d2ff8318b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_bp = np.array(['ear_left','ear_right', 'lateral_left','lateral_right','neck','nose','tail_base']).astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b757021-becf-481b-9d85-d0424810b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(columns=['lab_id', 'video_id', 'mouse_1', 'mouse_2', 'chunk', 'ok'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8dc9fa-82ce-40cd-9f0b-39cfbc9240af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocess, base_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bffa95-afd2-4b60-bf30-bdba86ab1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_track(track, fps):\n",
    "    pdist = torch.nn.PairwiseDistance(p=2)\n",
    "\n",
    "    x = torch.tensor(np.stack([np.stack([np.array(_x) for _x in x]) for x in track.values]))\n",
    "    if x.size(1)==7: x = torch.cat([x,x], dim=1)\n",
    "    \n",
    "\n",
    "    resize_x = torchvision.transforms.Resize((int(len(x)*(30./fps)), 2))\n",
    "    \n",
    "    x_ = []\n",
    "    for i in range(14):\n",
    "        x_.append(resize_x(x[:,i].unsqueeze(0))[0].unsqueeze(1) / ppc)\n",
    "    x = torch.cat(x_, dim=1)\n",
    "    \n",
    "    return x.float()\n",
    "\n",
    "\n",
    "def get_behaviors_labeled(x):\n",
    "    if isinstance(x, str):\n",
    "        B = {}\n",
    "        X = eval(x)\n",
    "        for x in X:\n",
    "            m1,m2,b = x.split(',')\n",
    "            if (m1,m2) in B: B[(m1,m2)].append(b.replace('\"', '').replace(\"'\", ''))\n",
    "            else: B[(m1,m2)] = [b.replace('\"', '').replace(\"'\", '')]\n",
    "\n",
    "        for p in B:\n",
    "            vec = torch.zeros((len(LABELS)))\n",
    "            for x in B[p]: vec[LABELS.index(x)] = 1\n",
    "            vec[-1]=1\n",
    "            B[p] = vec\n",
    "        return B\n",
    "    return {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adcd9c8-d736-453d-9c38-dd5214ee96af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mobile_average(x, kernel=[0.05,0.1,0.2,0.3,0.2,0.1,0.05]):\n",
    "    kernel = torch.tensor(kernel)\n",
    "    for _ in range(len(x.shape)-1): kernel = kernel.unsqueeze(-1)\n",
    "    k_size = len(kernel)//2\n",
    "    N = x.size(0)\n",
    "    out = x.clone()\n",
    "    for i in range(k_size, N-k_size):\n",
    "        out[i] = torch.multiply(x[i-k_size:i+k_size+1], kernel).sum(dim=0)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0f98b0-3f9c-4a15-91de-fd5c8a23bcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Pred = pd.DataFrame(columns=['row_id','video_id','agent_id','target_id','action','start_frame','stop_frame'])\n",
    "model.eval()\n",
    "\n",
    "\n",
    "for idx in tqdm(df.index[4:5]):\n",
    "    filepath = f'{df.loc[idx, 'lab_id']}/{df.loc[idx, 'video_id']}'\n",
    "    track = pd.read_parquet(PATH+f'train_tracking/{filepath}.parquet')\n",
    "    annot = pd.read_parquet(PATH+f'train_annotation/{filepath}.parquet')\n",
    "    annot['video_id'] = df.loc[idx, 'video_id']\n",
    "    annot['lab_id'] = df.loc[idx, 'lab_id']\n",
    "    annot['behaviors_labeled'] = df.loc[idx, 'behaviors_labeled']\n",
    "\n",
    "    annot['agent_id'] = 'mouse'+annot['agent_id'].astype('str')\n",
    "    annot['target_id'] = 'mouse'+annot['target_id'].astype('str')\n",
    "    annot.loc[annot['agent_id']==annot['target_id'], 'target_id'] = 'self'\n",
    "\n",
    "\n",
    "    fps = df.loc[idx, 'frames_per_second']\n",
    "    ppc = df.loc[idx, 'pix_per_cm_approx']\n",
    "    min_coord = np.array([track.x.min(), track.y.min()])\n",
    "    arena_w,arena_h = np.array([track.x.max(), track.y.max()])-min_coord\n",
    "    \n",
    "\n",
    "    Behaviors = get_behaviors_labeled(df.loc[idx, 'behaviors_labeled'])\n",
    "    track, _, Mice = preprocess(track, None, False)\n",
    "\n",
    "\n",
    "    for c in track.columns:\n",
    "        track[c] = track[c].apply(lambda x: x if (isinstance(x, np.ndarray) and pd.isna([x]).sum()==0) else np.array([0., 0.]))\n",
    "\n",
    "    context = torch.tensor([\n",
    "        float(df.loc[idx,'arena_shape']=='circular'),\n",
    "        arena_w/ppc,\n",
    "        arena_h/ppc,\n",
    "    ]).float().unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "    n_feat = 14\n",
    "    seq_len = 1024\n",
    "    min_size = 8\n",
    "\n",
    "    for m1 in Mice:\n",
    "        for m2 in Mice:\n",
    "            cols = list(base_bp + ' - ' + str(m1))\n",
    "            if m1!=m2: cols += list(base_bp + ' - ' + str(m2))\n",
    "            out = track[cols]\n",
    "\n",
    "            M1 = f'mouse{m1}'\n",
    "            M2 = f'mouse{m2}' if m1!=m2 else 'self'\n",
    "\n",
    "            if not ((M1,M2) in Behaviors): continue\n",
    "\n",
    "            with torch.no_grad():\n",
    "                X = load_track(out, fps).to(device)\n",
    "                length = len(X)\n",
    "                X = torch.cat([X, torch.zeros((seq_len-(X.size(0)%seq_len),n_feat,2)).to(device)], dim=0)\n",
    "                X = X.reshape((X.size(0)//seq_len, seq_len, n_feat, 2)).transpose(1,2)\n",
    "\n",
    "                yp = torch.zeros((X.size(0), 37, seq_len)).to(device)\n",
    "                yp = model(X,context.repeat(X.size(0),1)).sigmoid()\n",
    "                yp = yp.transpose(1,2).flatten(0,1).cpu()\n",
    "                yp = yp * Behaviors[(M1,M2)][:-1]\n",
    "\n",
    "                yp = resize_back(yp[:length].unsqueeze(0))[0]\n",
    "                \n",
    "            # yp = mobile_average(yp)\n",
    "            \n",
    "            last = (-1, 37)\n",
    "            P = []\n",
    "            for i,(m,p) in enumerate(zip(*yp.max(dim=1))):\n",
    "                p = int(p) if m>.2 else 37\n",
    "                if last[1]!=p:  \n",
    "                    \n",
    "                    p_len = len(Pred)\n",
    "                    # Add action\n",
    "                    if last[1]!=37 and (i-last[0]>min_size or len(P)==0):\n",
    "                        Pred.loc[p_len] = [p_len, df.loc[idx, 'video_id'], M1, M2, LABELS[last[1]], last[0], i-1]\n",
    "                        P.append(last)\n",
    "                        last = (i,int(p))\n",
    "                    elif i-last[0]<=min_size and P:\n",
    "                        last = P[-1]\n",
    "                    else:\n",
    "                        P.append(last)\n",
    "                        last = (i,int(p))\n",
    "                \n",
    "            if last[1] and last[1]!=37 and i-last[0]>min_size:\n",
    "                Pred.loc[len(Pred)] = [len(Pred), df.loc[idx, 'video_id'], M1, M2, LABELS[last[1]], last[0], i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa923a32-f369-4320-8505-b2531b495b5e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "class HostVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def single_lab_f1(lab_solution: pl.DataFrame, lab_submission: pl.DataFrame, beta: float = 1) -> float:\n",
    "    label_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
    "    prediction_frames: defaultdict[str, set[int]] = defaultdict(set)\n",
    "\n",
    "    for row in lab_solution.to_dicts():\n",
    "        label_frames[row['label_key']].update(range(row['start_frame'], row['stop_frame']))\n",
    "\n",
    "    for video in lab_solution['video_id'].unique():\n",
    "        \n",
    "        active_labels: str = lab_solution.filter(pl.col('video_id') == video)['behaviors_labeled'].first()  # ty: ignore\n",
    "        active_labels: set[str] = set(json.loads(active_labels))\n",
    "        predicted_mouse_pairs: defaultdict[str, set[int]] = defaultdict(set)\n",
    "\n",
    "        for row in lab_submission.filter(pl.col('video_id') == video).to_dicts():\n",
    "            # Since the labels are sparse, we can't evaluate prediction keys not in the active labels.\n",
    "            if ','.join([str(row['agent_id']), str(row['target_id']), row['action']]) not in active_labels:\n",
    "                continue\n",
    "\n",
    "            new_frames = set(range(row['start_frame'], row['stop_frame']))\n",
    "            # Ignore truly redundant predictions.\n",
    "            new_frames = new_frames.difference(prediction_frames[row['prediction_key']])\n",
    "            prediction_pair = ','.join([str(row['agent_id']), str(row['target_id'])])\n",
    "            if predicted_mouse_pairs[prediction_pair].intersection(new_frames):\n",
    "                # A single agent can have multiple targets per frame (ex: evading all other mice) but only one action per target per frame.\n",
    "                raise HostVisibleError('Multiple predictions for the same frame from one agent/target pair')\n",
    "            prediction_frames[row['prediction_key']].update(new_frames)\n",
    "            predicted_mouse_pairs[prediction_pair].update(new_frames)\n",
    "            \n",
    "    tps = defaultdict(int)\n",
    "    fns = defaultdict(int)\n",
    "    fps = defaultdict(int)\n",
    "\n",
    "    #print(list(prediction_frames))\n",
    "    \n",
    "    for key, pred_frames in prediction_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        matched_label_frames = label_frames[key]\n",
    "        \n",
    "        tps[action] += len(pred_frames.intersection(matched_label_frames))\n",
    "        fns[action] += len(matched_label_frames.difference(pred_frames))\n",
    "        fps[action] += len(pred_frames.difference(matched_label_frames))\n",
    "\n",
    "        # print(action, len(pred_frames), len(matched_label_frames))\n",
    "        # print(len(pred_frames.intersection(matched_label_frames)), len(matched_label_frames.difference(pred_frames)), len(pred_frames.difference(matched_label_frames)))\n",
    "        # print()\n",
    "\n",
    "    distinct_actions = set()\n",
    "    for key, frames in label_frames.items():\n",
    "        action = key.split('_')[-1]\n",
    "        distinct_actions.add(action)\n",
    "        if key not in prediction_frames:\n",
    "            fns[action] += len(frames)\n",
    "\n",
    "    action_f1s = []\n",
    "    for action in distinct_actions:\n",
    "        if tps[action] + fns[action] + fps[action] == 0:\n",
    "            action_f1s.append(0)\n",
    "        else:\n",
    "            action_f1s.append((1 + beta**2) * tps[action] / ((1 + beta**2) * tps[action] + beta**2 * fns[action] + fps[action]))\n",
    "    \n",
    "    print(action_f1s)\n",
    "    return sum(action_f1s) / len(action_f1s)\n",
    "\n",
    "\n",
    "def mouse_fbeta(solution: pd.DataFrame, submission: pd.DataFrame, beta: float = 1) -> float:\n",
    "    \n",
    "    if len(solution) == 0 or len(submission) == 0:\n",
    "        raise ValueError('Missing solution or submission data')\n",
    "\n",
    "    expected_cols = ['video_id', 'agent_id', 'target_id', 'action', 'start_frame', 'stop_frame']\n",
    "\n",
    "    for col in expected_cols:\n",
    "        if col not in solution.columns:\n",
    "            raise ValueError(f'Solution is missing column {col}')\n",
    "        if col not in submission.columns:\n",
    "            raise ValueError(f'Submission is missing column {col}')\n",
    "\n",
    "    solution: pl.DataFrame = pl.DataFrame(solution)\n",
    "    submission: pl.DataFrame = pl.DataFrame(submission)\n",
    "    assert (solution['start_frame'] <= solution['stop_frame']).all()\n",
    "    assert (submission['start_frame'] <= submission['stop_frame']).all()\n",
    "    solution_videos = set(solution['video_id'].unique())\n",
    "    # Need to align based on video IDs as we can't rely on the row IDs for handling public/private splits.\n",
    "    submission = submission.filter(pl.col('video_id').is_in(solution_videos))\n",
    "\n",
    "    solution = solution.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('label_key'),\n",
    "    )\n",
    "    submission = submission.with_columns(\n",
    "        pl.concat_str(\n",
    "            [\n",
    "                pl.col('video_id').cast(pl.Utf8),\n",
    "                pl.col('agent_id').cast(pl.Utf8),\n",
    "                pl.col('target_id').cast(pl.Utf8),\n",
    "                pl.col('action'),\n",
    "            ],\n",
    "            separator='_',\n",
    "        ).alias('prediction_key'),\n",
    "    )\n",
    "\n",
    "    lab_scores = []\n",
    "    for lab in solution['lab_id'].unique():\n",
    "        lab_solution = solution.filter(pl.col('lab_id') == lab).clone()\n",
    "        lab_videos = set(lab_solution['video_id'].unique())\n",
    "        lab_submission = submission.filter(pl.col('video_id').is_in(lab_videos)).clone()\n",
    "        lab_scores.append(single_lab_f1(lab_solution, lab_submission, beta=beta))\n",
    "\n",
    "    return sum(lab_scores) / len(lab_scores)\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, beta: float = 1) -> float:\n",
    "    \"\"\"\n",
    "    F1 score for the MABe Challenge\n",
    "    \"\"\"\n",
    "    solution = solution.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    submission = submission.drop(row_id_column_name, axis='columns', errors='ignore')\n",
    "    return mouse_fbeta(solution, submission, beta=beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d78ab-9641-4c86-81ae-867bb290c209",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred['lab_id'] = 'lab'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24ded07-16ee-4916-8799-d155a79d2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pred = Pred[Pred.start_frame<2048]\n",
    "#annot = annot[annot.start_frame<2048]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce5682-82a4-4d6a-8b23-928ba5edcef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "score(annot, Pred, 'row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ef134-57ea-4ab5-b401-d064eba96d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = idx\n",
    "(df.loc[i, 'lab_id'] + ' - ' + str(df.loc[i, 'video_id'])) in ds.DF.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d761f6ee-8f44-409f-9f85-9bcf87b1597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f17014-a72f-4d59-b5f6-d964d523b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8d88bd-a3c0-49cf-a256-883788f9acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.animation as animation\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.rcParams[\"animation.html\"] = \"jshtml\"\n",
    "# plt.rcParams['figure.dpi'] = 128  \n",
    "# plt.ioff()\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# colors = plt.cm.tab10.colors\n",
    "\n",
    "# def update(frame):\n",
    "#     plt.cla()\n",
    "    \n",
    "#     loc = x.cpu().transpose(0,-1)\n",
    "#     plt.scatter(loc[0,frame,:7], loc[1,frame,:7], c=colors[0])\n",
    "#     plt.scatter(loc[0,frame,7:], loc[1,frame,7:], c=colors[1])\n",
    "\n",
    "    \n",
    "#     if y[frame].max()>.5:\n",
    "#         plt.text(1,1, LABELS[np.argmax(y[frame])], color=colors[0])\n",
    "#     plt.xlim(0, 100)\n",
    "#     plt.ylim(0, 100)\n",
    "\n",
    "\n",
    "# ani = animation.FuncAnimation(fig=fig, func=update, frames=x.size(1), interval=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07968907-690e-4e3a-809e-5e858483dbf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e96705-ed55-4619-955c-32b914a6b412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b29595d-fb46-4039-93d1-0ff5cc2e3e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc97748f-4eb6-4178-86c6-1a0c6ae8c765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "Pred = pd.DataFrame(columns=['row_id','video_id','agent_id','target_id','action','start_frame','stop_frame'])\n",
    "df = pd.read_csv(PATH+'test.csv')\n",
    "\n",
    "for idx in tqdm(df.index):\n",
    "    filepath = f\"{df.loc[idx, 'lab_id']}/{df.loc[idx, 'video_id']}\"\n",
    "    track = pd.read_parquet(PATH+f'test_tracking/{filepath}.parquet')\n",
    "\n",
    "    fps = df.loc[idx, 'frames_per_second']\n",
    "    ppc = df.loc[idx, 'pix_per_cm_approx']\n",
    "    min_coord = np.array([track.x.min(), track.y.min()])\n",
    "    arena_w,arena_h = np.array([track.x.max(), track.y.max()])-min_coord\n",
    "    \n",
    "\n",
    "    Behaviors = get_behaviors_labeled(df.loc[idx, 'behaviors_labeled'])\n",
    "    track, _, Mice = preprocess(track, None)\n",
    "\n",
    "    resize_back = torchvision.transforms.Resize((len(track), 37))\n",
    "\n",
    "\n",
    "    for c in track.columns:\n",
    "        track[c] = track[c].apply(lambda x: x-min_coord if (isinstance(x, np.ndarray) and pd.isna([x]).sum()==0) else np.array([0., 0.]))\n",
    "\n",
    "    context = torch.tensor([\n",
    "        float(df.loc[idx,'arena_shape']=='circular'),\n",
    "        arena_w/ppc,\n",
    "        arena_h/ppc,\n",
    "    ]).float().unsqueeze(0).to(device)\n",
    "\n",
    "    n_feat = 14\n",
    "    seq_len = 1024\n",
    "    min_size = 8\n",
    "\n",
    "    for m1 in Mice:\n",
    "        for m2 in Mice:\n",
    "            cols = list(base_bp + ' - ' + str(m1))\n",
    "            if m1!=m2: cols += list(base_bp + ' - ' + str(m2))\n",
    "            out = track[cols]\n",
    "\n",
    "            M1 = f'mouse{m1}'\n",
    "            M2 = f'mouse{m2}' if m1!=m2 else 'self'\n",
    "\n",
    "            if not ((M1,M2) in Behaviors): continue\n",
    "\n",
    "            with torch.no_grad():\n",
    "                X = load_track(out, fps).to(device)\n",
    "                length = len(X)\n",
    "                X = torch.cat([X, torch.zeros((seq_len-(X.size(0)%seq_len),n_feat,2)).to(device)], dim=0)\n",
    "                X = X.reshape((X.size(0)//seq_len, seq_len, n_feat, 2)).transpose(1,2)\n",
    "\n",
    "                yp = torch.zeros((X.size(0), 37, seq_len)).to(device)\n",
    "                yp = model(X,context.repeat(X.size(0),1)).sigmoid()\n",
    "                yp = yp.transpose(1,2).flatten(0,1).cpu()\n",
    "                yp = yp * Behaviors[(M1,M2)][:-1]\n",
    "\n",
    "                yp = resize_back(yp[:length].unsqueeze(0))[0]\n",
    "                \n",
    "            # yp = mobile_average(yp)\n",
    "            \n",
    "            last = (-1, 37)\n",
    "            P = []\n",
    "            for i,(m,p) in enumerate(zip(*yp.max(dim=1))):\n",
    "                p = int(p) if m>.2 else 37\n",
    "                if last[1]!=p:  \n",
    "                    \n",
    "                    p_len = len(Pred)\n",
    "                    # Add action\n",
    "                    if last[1]!=37 and (i-last[0]>min_size or len(P)==0):\n",
    "                        Pred.loc[p_len] = [p_len, df.loc[idx, 'video_id'], M1, M2, LABELS[last[1]], last[0], i-1]\n",
    "                        P.append(last)\n",
    "                        last = (i,int(p))\n",
    "                    elif i-last[0]<=min_size and P:\n",
    "                        last = P[-1]\n",
    "                    else:\n",
    "                        P.append(last)\n",
    "                        last = (i,int(p))\n",
    "                \n",
    "            if last[1] and last[1]!=37 and i-last[0]>min_size:\n",
    "                Pred.loc[len(Pred)] = [len(Pred), df.loc[idx, 'video_id'], M1, M2, LABELS[last[1]], last[0], i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79320fb-5176-4e1c-a68c-84c2a8060c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred = Pred.drop_duplicates(subset=['video_id', 'agent_id', 'target_id', 'action', 'start_frame'], keep='last')\n",
    "Pred.row_id = np.arange(len(Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e4070d-5513-4e2f-930e-a054d67a8a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db4b81b-8ce1-488d-9211-c3aec915132e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7542f27-ad89-4f5f-8960-a0b4008b3d50",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff3a4e-7aec-4714-ad33-5855f1e78882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef472df-d8fe-4904-8396-8f1cfba57765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6586ebe8-accf-4020-b8d7-b3973d19ecfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdb95ea-45c3-4981-b93c-c19008562206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7586d47e-6db6-4cc6-aeeb-b782bebe1922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6aa40-bbb8-42b2-b552-27a03188bc54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
